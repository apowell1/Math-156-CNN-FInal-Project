{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "!pip install lime scikit-image matplotlib\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.datasets import mnist  # Only for dataset loading\n",
        "import cupy as cp  # GPU-based operations\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import abc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpugqwFJRYJ3",
        "outputId": "5c7ef242-5dd5-4f6e-c935-12e732700d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m266.2/275.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.5.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (11.0.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=e2fb1b228bb243ff940ff50726c39fcabe9c7c4df70dcb0b5594eac1f07ff7bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define im2col function\n",
        "def im2col(input_data, kernel_size, stride=1):\n",
        "    batch_size, channels, height, width = input_data.shape\n",
        "    kernel_height, kernel_width = kernel_size\n",
        "    out_height = (height - kernel_height) // stride + 1\n",
        "    out_width = (width - kernel_width) // stride + 1\n",
        "\n",
        "    # Initialize column matrix\n",
        "    cols = cp.zeros((batch_size, channels, kernel_height, kernel_width, out_height, out_width), dtype=input_data.dtype)\n",
        "\n",
        "    for y in range(kernel_height):\n",
        "        for x in range(kernel_width):\n",
        "            y_max = y + stride * out_height\n",
        "            x_max = x + stride * out_width\n",
        "            cols[:, :, y, x, :, :] = input_data[:, :, y:y_max:stride, x:x_max:stride]\n",
        "\n",
        "    cols = cols.transpose(0, 3, 1, 2, 4, 5).reshape(batch_size * out_height * out_width, -1)\n",
        "    return cols\n",
        "\n",
        "# Define col2im function\n",
        "def col2im(cols, input_shape, kernel_size, stride=1):\n",
        "    \"\"\"\n",
        "    Converts column representation back to the original input tensor shape.\n",
        "\n",
        "    :param cols: Gradient columns of shape (batch_size * out_height * out_width, in_channels * kernel_height * kernel_width)\n",
        "    :param input_shape: Shape of the input tensor (batch_size, in_channels, height, width)\n",
        "    :param kernel_size: Tuple of (kernel_height, kernel_width)\n",
        "    :param stride: Stride of the convolution\n",
        "    :return: Gradient with respect to the input tensor, shape (batch_size, in_channels, height, width)\n",
        "    \"\"\"\n",
        "    batch_size, in_channels, height, width = input_shape\n",
        "    kernel_height, kernel_width = kernel_size\n",
        "    out_height = (height - kernel_height) // stride + 1\n",
        "    out_width = (width - kernel_width) // stride + 1\n",
        "\n",
        "    # Initialize the gradient input tensor\n",
        "    grad_input_padded = cp.zeros(input_shape, dtype=cols.dtype)\n",
        "\n",
        "    # Reshape cols to (batch_size, out_height, out_width, in_channels, kernel_height, kernel_width)\n",
        "    cols_reshaped = cols.reshape(batch_size, out_height, out_width, in_channels, kernel_height, kernel_width)\n",
        "\n",
        "    # Transpose to (batch_size, in_channels, out_height, out_width, kernel_height, kernel_width)\n",
        "    cols_reshaped = cols_reshaped.transpose(0, 3, 1, 2, 4, 5)\n",
        "\n",
        "    # Iterate over the kernel height and width to accumulate gradients\n",
        "    for y in range(kernel_height):\n",
        "        for x in range(kernel_width):\n",
        "            grad_input_padded[:, :, y:y + stride*out_height:stride, x:x + stride*out_width:stride] += cols_reshaped[:, :, :, :, y, x]\n",
        "\n",
        "    return grad_input_padded"
      ],
      "metadata": {
        "id": "klqw9HNARYHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base module class for layers\n",
        "class Module(abc.ABC):\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.weights = {}\n",
        "        self.grad_weights = {}\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def forward(self, input):\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def backward(self, grad_output):\n",
        "        pass\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.name\n",
        "\n",
        "# Composition for stacking layers\n",
        "class Composition(Module):\n",
        "    def __init__(self, submodules):\n",
        "        super().__init__(f\"Composition({', '.join(sub.name for sub in submodules)})\")\n",
        "        self.submodules = submodules\n",
        "\n",
        "        # Aggregate weights from submodules with unique keys\n",
        "        self.weights = {}\n",
        "        for sub in self.submodules:\n",
        "            self.weights.update({\n",
        "                f'{sub.name}.{w_name}': weight\n",
        "                for w_name, weight in sub.weights.items()\n",
        "            })\n",
        "\n",
        "    def forward(self, input):\n",
        "        for submodule in self.submodules:\n",
        "            input = submodule.forward(input)\n",
        "        return input\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        for submodule in reversed(self.submodules):\n",
        "            grad_output = submodule.backward(grad_output)\n",
        "        # Aggregate gradients from submodules\n",
        "        self.grad_weights = {}\n",
        "        for sub in self.submodules:\n",
        "            self.grad_weights.update({\n",
        "                f'{sub.name}.{w_name}': grad_weight\n",
        "                for w_name, grad_weight in sub.grad_weights.items()\n",
        "            })\n",
        "        return grad_output"
      ],
      "metadata": {
        "id": "1bxqLP6ORYFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized Convolutional Layer Using im2col and col2im (corrected)\n",
        "class Convolution(Module):\n",
        "    def __init__(self, name, in_channels, out_channels, kernel_size, padding=0, stride=1):\n",
        "        super().__init__(name)\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "\n",
        "        # He initialization for weights\n",
        "        self.weights = {\n",
        "            'W': cp.random.randn(out_channels, in_channels * kernel_size[0] * kernel_size[1]).astype(cp.float32) * cp.sqrt(2. / (in_channels * kernel_size[0] * kernel_size[1])),\n",
        "            'b': cp.zeros(out_channels, dtype=cp.float32)\n",
        "        }\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        batch_size, channels, height, width = input.shape\n",
        "        kernel_height, kernel_width = self.kernel_size\n",
        "        stride = self.stride\n",
        "\n",
        "        # Apply padding\n",
        "        if self.padding > 0:\n",
        "            input_padded = cp.pad(input, ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)), mode='constant')\n",
        "        else:\n",
        "            input_padded = input\n",
        "\n",
        "        self.input_padded = input_padded\n",
        "        _, _, padded_height, padded_width = input_padded.shape\n",
        "\n",
        "        # Compute output dimensions\n",
        "        out_height = (padded_height - kernel_height) // stride + 1\n",
        "        out_width = (padded_width - kernel_width) // stride + 1\n",
        "\n",
        "        # Convert input to columns\n",
        "        self.cols = im2col(input_padded, self.kernel_size, self.stride)  # Shape: (batch_size*out_height*out_width, in_channels*kernel_height*kernel_width)\n",
        "\n",
        "        # Reshape weights\n",
        "        W = self.weights['W']  # Shape: (out_channels, in_channels*kernel_height*kernel_width)\n",
        "\n",
        "        # Perform matrix multiplication\n",
        "        out = self.cols @ W.T + self.weights['b'][None, :]  # Shape: (batch_size*out_height*out_width, out_channels)\n",
        "\n",
        "        # Reshape output\n",
        "        out = out.reshape(batch_size, out_height, out_width, self.out_channels).transpose(0, 3, 1, 2)  # Shape: (batch_size, out_channels, out_height, out_width\n",
        "        return out\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        batch_size, out_channels, out_height, out_width = grad_output.shape\n",
        "\n",
        "        # Reshape grad_output to (batch_size*out_height*out_width, out_channels)\n",
        "        grad_output_reshaped = grad_output.transpose(0, 2, 3, 1).reshape(-1, out_channels)  # Shape: (batch_size*out_height*out_width, out_channels)\n",
        "\n",
        "        # Compute gradients w.r.t weights and biases\n",
        "        grad_W = grad_output_reshaped.T @ self.cols  # Shape: (out_channels, in_channels*kernel_height*kernel_width)\n",
        "        grad_b = grad_output_reshaped.sum(axis=0)  # Shape: (out_channels,)\n",
        "\n",
        "        # Compute gradients w.r.t input columns\n",
        "        W = self.weights['W']  # Shape: (out_channels, in_channels*kernel_height*kernel_width)\n",
        "        grad_cols = grad_output_reshaped @ W  # Shape: (batch_size*out_height*out_width, in_channels*kernel_height*kernel_width)\n",
        "\n",
        "        # Compute grad_input_padded using the corrected col2im\n",
        "        grad_input_padded = col2im(grad_cols, self.input_padded.shape, self.kernel_size, self.stride)\n",
        "\n",
        "        # Remove padding if applied\n",
        "        if self.padding > 0:\n",
        "            grad_input = grad_input_padded[:, :, self.padding:-self.padding, self.padding:-self.padding]\n",
        "        else:\n",
        "            grad_input = grad_input_padded\n",
        "\n",
        "        # Store gradients\n",
        "        self.grad_weights['W'] = grad_W\n",
        "        self.grad_weights['b'] = grad_b\n",
        "\n",
        "        return grad_input\n",
        "\n",
        "# Linear (Fully Connected) Layer\n",
        "class Linear(Module):\n",
        "    def __init__(self, name='Linear', n_in_features=256, n_out_features=10):\n",
        "        super().__init__(name)\n",
        "        stdv = 1.0 / cp.sqrt(n_in_features)\n",
        "        self.weights = {\n",
        "            'W': cp.random.uniform(-stdv, stdv, (n_out_features, n_in_features)).astype(cp.float32),\n",
        "            'b': cp.random.uniform(-stdv, stdv, (n_out_features,)).astype(cp.float32)\n",
        "        }\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return input @ self.weights['W'].T + self.weights['b']\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        # Compute gradients w.r.t weights and biases\n",
        "        grad_W = grad_output.T @ self.input  # Shape: (n_out_features, n_in_features)\n",
        "        grad_b = cp.sum(grad_output, axis=0)  # Shape: (n_out_features,)\n",
        "\n",
        "        # Compute gradient w.r.t input\n",
        "        grad_input = grad_output @ self.weights['W']\n",
        "\n",
        "        # Store gradients\n",
        "        self.grad_weights['W'] = grad_W\n",
        "        self.grad_weights['b'] = grad_b\n",
        "\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "# Flatten Layer\n",
        "class Flatten(Module):\n",
        "    def __init__(self, name='Flatten'):\n",
        "        super().__init__(name)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input_shape = input.shape\n",
        "        batch_size = input.shape[0]\n",
        "        return input.reshape(batch_size, -1)\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        return grad_output.reshape(self.input_shape)"
      ],
      "metadata": {
        "id": "mK4jCSQhRYAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ReLU Activation Layer\n",
        "class ReLU(Module):\n",
        "    def __init__(self, name='ReLU'):\n",
        "        super().__init__(name)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return cp.maximum(0, input)  # Apply ReLU on GPU\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        return grad_output * (self.input > 0)  # Gradient pass-through for positive inputs\n",
        "\n",
        "# Response Normalization Activation Layer (Optimized and Vectorized)\n",
        "class ResponseNormalization(Module):\n",
        "    def __init__(self, name='ResponseNormalization', alpha=0.05, beta=0.5, k=1.0):\n",
        "        \"\"\"\n",
        "        Initialize the Response Normalization layer.\n",
        "        :param alpha: Scaling parameter in the normalization formula\n",
        "        :param beta: Exponent parameter in the normalization formula\n",
        "        :param k: Bias term to avoid division by zero\n",
        "        \"\"\"\n",
        "        super().__init__(name)\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.k = k\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Forward pass for the response normalization layer.\n",
        "        :param input: Input tensor of shape (batch_size, depth, height, width)\n",
        "        :return: Normalized tensor of the same shape\n",
        "        \"\"\"\n",
        "        self.input = input\n",
        "        # Compute squared input\n",
        "        squared_input = input ** 2\n",
        "        # Compute the normalization denominator\n",
        "        self.norm = (self.k + (self.alpha / 2) * cp.sum(squared_input, axis=1, keepdims=True)) ** self.beta\n",
        "        # Normalize the input\n",
        "        output = input / self.norm\n",
        "        return output\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        \"\"\"\n",
        "        Backward pass for the response normalization layer.\n",
        "        :param grad_output: Gradient of the loss w.r.t. the output tensor\n",
        "        :return: Gradient of the loss w.r.t. the input tensor\n",
        "        \"\"\"\n",
        "        # Compute gradient w.r.t input\n",
        "        grad_input = (grad_output / self.norm) - (self.alpha * self.beta * self.input * cp.sum(self.input * grad_output, axis=1, keepdims=True) / (self.norm ** (self.beta + 1)))\n",
        "        return grad_input\n",
        "\n",
        "# Softmax Activation Layer\n",
        "class Softmax(Module):\n",
        "    def __init__(self, name='Softmax'):\n",
        "        super().__init__(name)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Shift input for numerical stability\n",
        "        input_shifted = input - cp.max(input, axis=1, keepdims=True)\n",
        "        exp_scores = cp.exp(input_shifted)\n",
        "        self.output = exp_scores / cp.sum(exp_scores, axis=1, keepdims=True)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        \"\"\"\n",
        "        Compute the gradient of the loss with respect to the input of the Softmax layer.\n",
        "        :param grad_output: Gradient from the loss with respect to the Softmax output.\n",
        "        :return: Gradient with respect to the input of the Softmax layer.\n",
        "        \"\"\"\n",
        "        # Compute the gradient for each sample in the batch\n",
        "        grad_input = cp.zeros_like(self.output)\n",
        "        for i in range(self.output.shape[0]):\n",
        "            y = self.output[i].reshape(-1, 1)\n",
        "            jacobian = cp.diagflat(y) - cp.dot(y, y.T)\n",
        "            grad_input[i] = cp.dot(jacobian, grad_output[i])\n",
        "        return grad_input"
      ],
      "metadata": {
        "id": "BZYIE0wsRX33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected Stochastic Pooling Layer\n",
        "class StochasticPooling(Module):\n",
        "    def __init__(self, name='StochasticPooling', pool_size=(2, 2)):\n",
        "        \"\"\"\n",
        "        Initialize the Stochastic Pooling layer.\n",
        "        :param pool_size: Tuple (height, width) specifying the pooling region size.\n",
        "        \"\"\"\n",
        "        super().__init__(name)\n",
        "        self.pool_size = pool_size\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Forward pass for stochastic pooling.\n",
        "        :param input: 4D tensor (batch_size, channels, height, width)\n",
        "        :return: Output with reduced spatial dimensions\n",
        "        \"\"\"\n",
        "        self.input = input\n",
        "        batch_size, channels, height, width = input.shape\n",
        "        pool_h, pool_w = self.pool_size\n",
        "        out_h = height // pool_h\n",
        "        out_w = width // pool_w\n",
        "\n",
        "        # Reshape input to (batch_size, channels, out_h, out_w, pool_h * pool_w)\n",
        "        input_reshaped = input.reshape(batch_size, channels, out_h, pool_h, out_w, pool_w)\n",
        "        input_reshaped = input_reshaped.transpose(0, 1, 2, 4, 3, 5).reshape(batch_size, channels, out_h, out_w, pool_h * pool_w)\n",
        "\n",
        "        # Compute probabilities using absolute values\n",
        "        abs_input = cp.abs(input_reshaped)\n",
        "        sum_abs = cp.sum(abs_input, axis=-1, keepdims=True)\n",
        "        probabilities = abs_input / (sum_abs + 1e-12)  # Prevent division by zero\n",
        "\n",
        "        # Compute cumulative probabilities along the last axis\n",
        "        cumulative_probs = cp.cumsum(probabilities, axis=-1)\n",
        "\n",
        "        # Generate random numbers for sampling\n",
        "        random_vals = cp.random.rand(batch_size, channels, out_h, out_w, 1)\n",
        "\n",
        "        # Determine the sampled indices\n",
        "        sampled_indices_flat = cp.sum(cumulative_probs <= random_vals, axis=-1) - 1\n",
        "        sampled_indices_flat = cp.clip(sampled_indices_flat, 0, pool_h * pool_w - 1)  # Ensure indices are within bounds\n",
        "\n",
        "        self.sampled_indices_flat = sampled_indices_flat.copy()\n",
        "\n",
        "        # Convert flat indices back to (h, w) indices within the pooling window\n",
        "        sampled_indices_h = sampled_indices_flat // pool_w\n",
        "        sampled_indices_w = sampled_indices_flat % pool_w\n",
        "\n",
        "        # Prepare indices for advanced indexing\n",
        "        batch_indices = cp.arange(batch_size)[:, None, None, None]\n",
        "        channel_indices = cp.arange(channels)[None, :, None, None]\n",
        "        out_h_indices = cp.arange(out_h)[None, None, :, None]\n",
        "        out_w_indices = cp.arange(out_w)[None, None, None, :]\n",
        "\n",
        "        # Broadcast indices to match the shape\n",
        "        batch_indices = cp.broadcast_to(batch_indices, (batch_size, channels, out_h, out_w))\n",
        "        channel_indices = cp.broadcast_to(channel_indices, (batch_size, channels, out_h, out_w))\n",
        "        out_h_indices = cp.broadcast_to(out_h_indices, (batch_size, channels, out_h, out_w))\n",
        "        out_w_indices = cp.broadcast_to(out_w_indices, (batch_size, channels, out_h, out_w))\n",
        "\n",
        "        # Gather the sampled values\n",
        "        output = input_reshaped[\n",
        "            batch_indices,\n",
        "            channel_indices,\n",
        "            out_h_indices,\n",
        "            out_w_indices,\n",
        "            sampled_indices_flat\n",
        "        ]\n",
        "\n",
        "        return output\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        \"\"\"\n",
        "        Backward pass for stochastic pooling.\n",
        "        :param grad_output: Gradient of loss with respect to output\n",
        "        :return: Gradient of loss with respect to input\n",
        "        \"\"\"\n",
        "        batch_size, channels, out_h, out_w = grad_output.shape\n",
        "        pool_h, pool_w = self.pool_size\n",
        "\n",
        "        # Initialize gradient w.r.t input\n",
        "        grad_input = cp.zeros_like(self.input, dtype=cp.float32)\n",
        "\n",
        "        # Convert flat indices back to (h, w) indices\n",
        "        sampled_indices_h = self.sampled_indices_flat // pool_w\n",
        "        sampled_indices_w = self.sampled_indices_flat % pool_w\n",
        "\n",
        "        # Prepare indices for gradient scattering\n",
        "        batch_indices = cp.arange(batch_size)[:, None, None, None]\n",
        "        channel_indices = cp.arange(channels)[None, :, None, None]\n",
        "        out_h_indices = cp.arange(out_h)[None, None, :, None]\n",
        "        out_w_indices = cp.arange(out_w)[None, None, None, :]\n",
        "\n",
        "        # Broadcast indices to match the shape\n",
        "        batch_indices = cp.broadcast_to(batch_indices, (batch_size, channels, out_h, out_w))\n",
        "        channel_indices = cp.broadcast_to(channel_indices, (batch_size, channels, out_h, out_w))\n",
        "        out_h_indices = cp.broadcast_to(out_h_indices, (batch_size, channels, out_h, out_w))\n",
        "        out_w_indices = cp.broadcast_to(out_w_indices, (batch_size, channels, out_h, out_w))\n",
        "\n",
        "        # Scatter gradients back to input\n",
        "        grad_input[\n",
        "            batch_indices,\n",
        "            channel_indices,\n",
        "            out_h_indices * pool_h + sampled_indices_h,\n",
        "            out_w_indices * pool_w + sampled_indices_w\n",
        "        ] += grad_output\n",
        "\n",
        "        return grad_input"
      ],
      "metadata": {
        "id": "60gPeiuex_lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combined Softmax and Cross-Entropy Loss\n",
        "class SoftmaxCrossEntropy(Module):\n",
        "    def __init__(self, name='SoftmaxCrossEntropy'):\n",
        "        super().__init__(name)\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        \"\"\"\n",
        "        Forward pass combining Softmax activation and Categorical Cross-Entropy loss.\n",
        "        :param input: Logits (batch_size, num_classes)\n",
        "        :param target: True labels as one-hot vectors (batch_size, num_classes)\n",
        "        :return: Scalar loss value\n",
        "        \"\"\"\n",
        "        # Shift input for numerical stability\n",
        "        input_shifted = input - cp.max(input, axis=1, keepdims=True)\n",
        "        exp_scores = cp.exp(input_shifted)\n",
        "        self.output = exp_scores / cp.sum(exp_scores, axis=1, keepdims=True)\n",
        "        self.target = target\n",
        "        self.loss = -cp.sum(target * cp.log(self.output + 1e-12)) / input.shape[0]\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self):\n",
        "        \"\"\"\n",
        "        Backward pass for combined Softmax and Categorical Cross-Entropy.\n",
        "        :return: Gradient with respect to input logits\n",
        "        \"\"\"\n",
        "        grad_input = (self.output - self.target) / self.target.shape[0]\n",
        "        return grad_input\n",
        "\n",
        "# Mini-Batch SGD Optimizer (corrected)\n",
        "class MiniBatchSGD:\n",
        "    def __init__(self, module, lr=1e-3, batch_size=32):\n",
        "        self.module = module\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def step(self):\n",
        "        for name, grad in self.module.grad_weights.items():\n",
        "            if name.endswith('.W') or name.endswith('.b'):\n",
        "                if name in self.module.weights:\n",
        "                    self.module.weights[name] -= self.lr * grad\n",
        "                else:\n",
        "                    raise KeyError(f\"Weight key '{name}' not found in module.weights.\")"
      ],
      "metadata": {
        "id": "hHjuhDy9ycN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model without SoftmaxCrossEntropy\n",
        "def create_cnn_model():\n",
        "    return Composition([\n",
        "        # First Convolution: 1x28x28 -> 16x25x25\n",
        "        Convolution(name='Conv1', in_channels=1, out_channels=16, kernel_size=(4, 4), padding=0, stride=1),\n",
        "        ReLU(name='ReLU1'),\n",
        "\n",
        "        # Second Convolution: 16x25x25 -> 32x24x24\n",
        "        Convolution(name='Conv2', in_channels=16, out_channels=32, kernel_size=(2, 2), padding=0, stride=1),\n",
        "        ResponseNormalization(name='Norm1', alpha=0.05, beta=0.5, k=1.0),\n",
        "\n",
        "        # First Stochastic Pooling: 32x24x24 -> 32x12x12\n",
        "        StochasticPooling(name='Pool1', pool_size=(2, 2)),\n",
        "\n",
        "        # Second Stochastic Pooling: 32x12x12 -> 32x6x6\n",
        "        StochasticPooling(name='Pool2', pool_size=(2, 2)),\n",
        "\n",
        "        # Third Convolution: 32x6x6 -> 64x4x4\n",
        "        Convolution(name='Conv3', in_channels=32, out_channels=64, kernel_size=(3, 3), padding=0, stride=1),\n",
        "\n",
        "        # Flatten: 64x4x4 -> 1024\n",
        "        Flatten(name='Flatten1'),\n",
        "\n",
        "        # Fully Connected Layer: 1024 -> 10\n",
        "        Linear(name='FC1', n_in_features=1024, n_out_features=10)\n",
        "    ])\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "def load_preprocess_data():\n",
        "    # Load MNIST data\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    print(\"Original training data shape:\", X_train.shape)\n",
        "    print(\"Original test data shape:\", X_test.shape)\n",
        "\n",
        "    # Normalize the images to [0, 1] and move to GPU\n",
        "    X_train = cp.asarray(X_train, dtype=cp.float32) / 255.0\n",
        "    X_test = cp.asarray(X_test, dtype=cp.float32) / 255.0\n",
        "\n",
        "    # Reshape the data to include the channel dimension (batch_size, channels, height, width)\n",
        "    X_train = X_train.reshape(-1, 1, 28, 28)\n",
        "    X_test = X_test.reshape(-1, 1, 28, 28)\n",
        "\n",
        "    print(\"Reshaped training data shape:\", X_train.shape)\n",
        "    print(\"Reshaped test data shape:\", X_test.shape)\n",
        "\n",
        "    # One-hot encode the labels and move to GPU\n",
        "    num_classes = 10\n",
        "    y_train = cp.eye(num_classes, dtype=cp.float32)[y_train]\n",
        "    y_test = cp.eye(num_classes, dtype=cp.float32)[y_test]\n",
        "\n",
        "    print(\"One-hot encoded training labels shape:\", y_train.shape)\n",
        "    print(\"One-hot encoded test labels shape:\", y_test.shape)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "# Instantiate the model, loss function, and optimizer\n",
        "def instantiate_components():\n",
        "    # Instantiate the model\n",
        "    model = create_cnn_model()\n",
        "\n",
        "    # Instantiate the loss function\n",
        "    loss_fn = SoftmaxCrossEntropy()\n",
        "\n",
        "    # Instantiate the optimizer\n",
        "    optimizer = MiniBatchSGD(module=model, lr=0.01, batch_size=32)\n",
        "\n",
        "    return model, loss_fn, optimizer\n",
        "\n",
        "def train_model(model, loss_fn, optimizer, X_train, y_train, num_epochs=10, batch_size=32):\n",
        "    # Convert training data back to CPU for shuffling and slicing\n",
        "    X_train_cpu = cp.asnumpy(X_train)\n",
        "    y_train_cpu = cp.asnumpy(y_train)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        permutation = np.random.permutation(X_train_cpu.shape[0])\n",
        "        X_train_cpu_shuffled = X_train_cpu[permutation]\n",
        "        y_train_cpu_shuffled = y_train_cpu[permutation]\n",
        "\n",
        "        epoch_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "\n",
        "        for start in range(0, X_train_cpu_shuffled.shape[0], batch_size):\n",
        "            end = start + batch_size\n",
        "            X_batch_cpu = X_train_cpu_shuffled[start:end]\n",
        "            y_batch_cpu = y_train_cpu_shuffled[start:end]\n",
        "\n",
        "            # Transfer batch to GPU\n",
        "            X_batch = cp.asarray(X_batch_cpu)\n",
        "            y_batch = cp.asarray(y_batch_cpu)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model.forward(X_batch)\n",
        "            loss = loss_fn.forward(logits, y_batch)\n",
        "            epoch_loss += loss\n",
        "\n",
        "            predictions = cp.argmax(loss_fn.output, axis=1)\n",
        "            targets = cp.argmax(y_batch, axis=1)\n",
        "            correct_predictions += cp.sum(predictions == targets)\n",
        "\n",
        "            # Backward pass\n",
        "            grad_loss = loss_fn.backward()\n",
        "            model.backward(grad_loss)\n",
        "            optimizer.step()\n",
        "\n",
        "            # Free GPU memory after each batch\n",
        "            del X_batch, y_batch, logits, grad_loss, predictions, targets\n",
        "            cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "        avg_loss = epoch_loss / (X_train_cpu.shape[0] / batch_size)\n",
        "        accuracy = correct_predictions / X_train_cpu.shape[0]\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f} - Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Free memory after training\n",
        "    del X_train_cpu, y_train_cpu, X_train_cpu_shuffled, y_train_cpu_shuffled\n",
        "    cp.get_default_memory_pool().free_all_blocks()"
      ],
      "metadata": {
        "id": "janzSU3RybVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LIME\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.segmentation import quickshift\n",
        "\n",
        "def explain_prediction(model, image, label, num_features=5, hide_rest=True):\n",
        "    # Convert CuPy array to NumPy and preprocess for LIME\n",
        "    image_np = image.get()[0].transpose(1, 2, 0)\n",
        "    if image_np.shape[-1] == 1:\n",
        "        image_np = np.repeat(image_np, 3, axis=-1)\n",
        "    image_np_resized = resize(image_np, (28, 28), anti_aliasing=True)\n",
        "\n",
        "    explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "    def predict_fn(images):\n",
        "        images_cp = cp.asarray(images, dtype=cp.float32).transpose(0, 3, 1, 2)\n",
        "        if images_cp.shape[1] == 3:\n",
        "            images_cp = (images_cp[:, 0, :, :] * 0.2989 +\n",
        "                         images_cp[:, 1, :, :] * 0.5870 +\n",
        "                         images_cp[:, 2, :, :] * 0.1140).reshape(images_cp.shape[0], 1, images_cp.shape[2], images_cp.shape[3])\n",
        "        logits = model.forward(images_cp)\n",
        "        probs = cp.exp(logits - cp.max(logits, axis=1, keepdims=True))\n",
        "        probs = probs / cp.sum(probs, axis=1, keepdims=True)\n",
        "        return probs.get()\n",
        "\n",
        "    segmentation_fn = lambda x: quickshift(x, kernel_size=1, max_dist=5, ratio=0.2)\n",
        "\n",
        "    explanation = explainer.explain_instance(\n",
        "        image_np_resized,\n",
        "        predict_fn,\n",
        "        labels=[label],\n",
        "        hide_color=0,\n",
        "        num_samples=1000,\n",
        "        segmentation_fn=segmentation_fn\n",
        "    )\n",
        "\n",
        "    temp, mask = explanation.get_image_and_mask(\n",
        "        label=label,\n",
        "        positive_only=False,  # Include both positive and negative contributions\n",
        "        num_features=num_features,\n",
        "        hide_rest=hide_rest\n",
        "    )\n",
        "\n",
        "    plt.imshow(mark_boundaries(temp, mask))\n",
        "    plt.title(f\"LIME Explanation for Class {label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "DkKUvCr5ER4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, loss_fn, X_test, y_test, batch_size=64, num_explanations=5):\n",
        "    num_samples = X_test.shape[0]\n",
        "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for i in tqdm(range(num_batches), desc=\"Evaluating\"):\n",
        "        start = i * batch_size\n",
        "        end = min(start + batch_size, num_samples)\n",
        "        X_batch = X_test[start:end]\n",
        "        y_batch = y_test[start:end]\n",
        "\n",
        "        # Forward pass: Get logits from the model\n",
        "        logits = model.forward(X_batch)\n",
        "\n",
        "        # Compute loss using the loss function\n",
        "        loss = loss_fn.forward(logits, y_batch)\n",
        "        total_loss += loss\n",
        "\n",
        "        # Compute probabilities using Softmax\n",
        "        softmax = Softmax()\n",
        "        probabilities = softmax.forward(logits)\n",
        "\n",
        "        # Compute predictions\n",
        "        predictions = cp.argmax(probabilities, axis=1)\n",
        "        targets = cp.argmax(y_batch, axis=1)\n",
        "        correct_predictions += cp.sum(predictions == targets)\n",
        "\n",
        "        # Free memory for the current batch\n",
        "        del X_batch, y_batch, logits, loss, probabilities, predictions, targets\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    # Calculate average loss and accuracy\n",
        "    avg_loss = total_loss / num_batches\n",
        "    accuracy = correct_predictions / num_samples\n",
        "    print(f\"Test Loss: {avg_loss:.4f} - Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Generate LIME explanations for a few test samples\n",
        "    print(\"\\nGenerating LIME explanations for sample predictions...\")\n",
        "    for idx in range(min(num_explanations, num_samples)):\n",
        "        image = X_test[idx:idx+1]\n",
        "        label = cp.argmax(y_test[idx]).item()\n",
        "        explain_prediction(model, image, label, num_features=5, hide_rest=True)\n",
        "\n",
        "\n",
        "def evaluate_in_batches(model, X, y, batch_size=64):\n",
        "    num_samples = X.shape[0]\n",
        "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
        "    correct = 0\n",
        "    for i in range(num_batches):\n",
        "        start = i * batch_size\n",
        "        end = min(start + batch_size, num_samples)\n",
        "        X_batch = X[start:end]\n",
        "        y_batch = y[start:end]\n",
        "        logits = model.forward(X_batch)\n",
        "        softmax = Softmax()\n",
        "        probs = softmax.forward(logits)\n",
        "        preds = cp.argmax(probs, axis=1)\n",
        "        targets = cp.argmax(y_batch, axis=1)\n",
        "        correct += cp.sum(preds == targets)\n",
        "        # Free GPU memory\n",
        "        del X_batch, y_batch, logits, probs, preds, targets\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "    return correct / num_samples\n",
        "\n",
        "def hyperparameter_tuning(X_train, y_train, X_test, y_test, hyperparams_list):\n",
        "    best_accuracy = -1\n",
        "    best_params = None\n",
        "\n",
        "    for params in hyperparams_list:\n",
        "        lr = params.get('lr', 0.001)\n",
        "        batch_size = params.get('batch_size', 64)\n",
        "        num_epochs = params.get('num_epochs', 10)\n",
        "\n",
        "        model = create_cnn_model()\n",
        "        loss_fn = SoftmaxCrossEntropy()\n",
        "        optimizer = MiniBatchSGD(module=model, lr=lr, batch_size=batch_size)\n",
        "\n",
        "        train_model(model, loss_fn, optimizer, X_train, y_train, num_epochs=num_epochs, batch_size=batch_size)\n",
        "\n",
        "        # Evaluate model in batches to avoid OOM\n",
        "        accuracy = evaluate_in_batches(model, X_test, y_test, batch_size=64)\n",
        "        print(f\"Hyperparams: lr={lr}, batch_size={batch_size}, num_epochs={num_epochs} -> Test Accuracy: {accuracy}\")\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_params = params\n",
        "\n",
        "    print(f\"Best Hyperparams: {best_params} with Test Accuracy: {best_accuracy}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X_train, y_train, X_test, y_test = load_preprocess_data()\n",
        "\n",
        "    hyperparams_list = [\n",
        "        {'lr': 0.001, 'batch_size': 64, 'num_epochs': 10},\n",
        "        {'lr': 0.005, 'batch_size': 32, 'num_epochs': 50},\n",
        "        {'lr': 0.0005, 'batch_size': 128, 'num_epochs': 100}\n",
        "    ]\n",
        "\n",
        "    hyperparameter_tuning(X_train, y_train, X_test, y_test, hyperparams_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBCNYTfTym2b",
        "outputId": "ae8c8f1c-10c0-4949-9d52-ce2b62978d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Original training data shape: (60000, 28, 28)\n",
            "Original test data shape: (10000, 28, 28)\n",
            "Reshaped training data shape: (60000, 1, 28, 28)\n",
            "Reshaped test data shape: (10000, 1, 28, 28)\n",
            "One-hot encoded training labels shape: (60000, 10)\n",
            "One-hot encoded test labels shape: (10000, 10)\n",
            "Epoch 1/10 - Loss: 2.0719 - Accuracy: 0.3293\n",
            "Epoch 2/10 - Loss: 1.6738 - Accuracy: 0.5832\n",
            "Epoch 3/10 - Loss: 1.4259 - Accuracy: 0.6507\n",
            "Epoch 4/10 - Loss: 1.2554 - Accuracy: 0.6876\n",
            "Epoch 5/10 - Loss: 1.1444 - Accuracy: 0.7036\n",
            "Epoch 6/10 - Loss: 1.0588 - Accuracy: 0.7204\n",
            "Epoch 7/10 - Loss: 0.9942 - Accuracy: 0.7318\n",
            "Epoch 8/10 - Loss: 0.9462 - Accuracy: 0.7361\n",
            "Epoch 9/10 - Loss: 0.9025 - Accuracy: 0.7440\n",
            "Epoch 10/10 - Loss: 0.8733 - Accuracy: 0.7507\n",
            "Hyperparams: lr=0.001, batch_size=64, num_epochs=10 -> Test Accuracy: 0.7604\n",
            "Epoch 1/50 - Loss: 1.3202 - Accuracy: 0.6408\n",
            "Epoch 2/50 - Loss: 0.8906 - Accuracy: 0.7384\n",
            "Epoch 3/50 - Loss: 0.7781 - Accuracy: 0.7592\n",
            "Epoch 4/50 - Loss: 0.6947 - Accuracy: 0.7788\n",
            "Epoch 5/50 - Loss: 0.6331 - Accuracy: 0.7975\n",
            "Epoch 6/50 - Loss: 0.5979 - Accuracy: 0.8080\n",
            "Epoch 7/50 - Loss: 0.5671 - Accuracy: 0.8166\n",
            "Epoch 8/50 - Loss: 0.5520 - Accuracy: 0.8227\n",
            "Epoch 9/50 - Loss: 0.5281 - Accuracy: 0.8317\n",
            "Epoch 10/50 - Loss: 0.5154 - Accuracy: 0.8363\n",
            "Epoch 11/50 - Loss: 0.5023 - Accuracy: 0.8419\n",
            "Epoch 12/50 - Loss: 0.4908 - Accuracy: 0.8452\n",
            "Epoch 13/50 - Loss: 0.4825 - Accuracy: 0.8468\n",
            "Epoch 14/50 - Loss: 0.4770 - Accuracy: 0.8512\n",
            "Epoch 15/50 - Loss: 0.4642 - Accuracy: 0.8548\n",
            "Epoch 16/50 - Loss: 0.4605 - Accuracy: 0.8552\n",
            "Epoch 17/50 - Loss: 0.4547 - Accuracy: 0.8579\n",
            "Epoch 18/50 - Loss: 0.4492 - Accuracy: 0.8593\n",
            "Epoch 19/50 - Loss: 0.4514 - Accuracy: 0.8597\n",
            "Epoch 20/50 - Loss: 0.4454 - Accuracy: 0.8608\n",
            "Epoch 21/50 - Loss: 0.4429 - Accuracy: 0.8601\n",
            "Epoch 22/50 - Loss: 0.4394 - Accuracy: 0.8619\n",
            "Epoch 23/50 - Loss: 0.4333 - Accuracy: 0.8637\n",
            "Epoch 24/50 - Loss: 0.4329 - Accuracy: 0.8637\n",
            "Epoch 25/50 - Loss: 0.4260 - Accuracy: 0.8659\n",
            "Epoch 26/50 - Loss: 0.4219 - Accuracy: 0.8688\n",
            "Epoch 27/50 - Loss: 0.4235 - Accuracy: 0.8663\n",
            "Epoch 28/50 - Loss: 0.4215 - Accuracy: 0.8681\n",
            "Epoch 29/50 - Loss: 0.4167 - Accuracy: 0.8704\n",
            "Epoch 30/50 - Loss: 0.4143 - Accuracy: 0.8700\n",
            "Epoch 31/50 - Loss: 0.4158 - Accuracy: 0.8688\n",
            "Epoch 32/50 - Loss: 0.4138 - Accuracy: 0.8701\n",
            "Epoch 33/50 - Loss: 0.4091 - Accuracy: 0.8703\n",
            "Epoch 34/50 - Loss: 0.4116 - Accuracy: 0.8710\n",
            "Epoch 35/50 - Loss: 0.4007 - Accuracy: 0.8745\n",
            "Epoch 36/50 - Loss: 0.4122 - Accuracy: 0.8709\n",
            "Epoch 37/50 - Loss: 0.4087 - Accuracy: 0.8718\n",
            "Epoch 38/50 - Loss: 0.4093 - Accuracy: 0.8718\n",
            "Epoch 39/50 - Loss: 0.4060 - Accuracy: 0.8702\n",
            "Epoch 40/50 - Loss: 0.4072 - Accuracy: 0.8728\n",
            "Epoch 41/50 - Loss: 0.4058 - Accuracy: 0.8725\n",
            "Epoch 42/50 - Loss: 0.4051 - Accuracy: 0.8708\n",
            "Epoch 43/50 - Loss: 0.4059 - Accuracy: 0.8734\n",
            "Epoch 44/50 - Loss: 0.4064 - Accuracy: 0.8726\n",
            "Epoch 45/50 - Loss: 0.4016 - Accuracy: 0.8726\n",
            "Epoch 46/50 - Loss: 0.3986 - Accuracy: 0.8735\n",
            "Epoch 47/50 - Loss: 0.3997 - Accuracy: 0.8737\n",
            "Epoch 48/50 - Loss: 0.4019 - Accuracy: 0.8728\n",
            "Epoch 49/50 - Loss: 0.3983 - Accuracy: 0.8749\n",
            "Epoch 50/50 - Loss: 0.4008 - Accuracy: 0.8730\n",
            "Hyperparams: lr=0.005, batch_size=32, num_epochs=50 -> Test Accuracy: 0.8759\n",
            "Epoch 1/100 - Loss: 2.2009 - Accuracy: 0.1991\n",
            "Epoch 2/100 - Loss: 1.9010 - Accuracy: 0.4557\n",
            "Epoch 3/100 - Loss: 1.6837 - Accuracy: 0.5821\n",
            "Epoch 4/100 - Loss: 1.5199 - Accuracy: 0.6394\n",
            "Epoch 5/100 - Loss: 1.3942 - Accuracy: 0.6741\n",
            "Epoch 6/100 - Loss: 1.2961 - Accuracy: 0.6960\n",
            "Epoch 7/100 - Loss: 1.2198 - Accuracy: 0.7073\n",
            "Epoch 8/100 - Loss: 1.1547 - Accuracy: 0.7197\n",
            "Epoch 9/100 - Loss: 1.1004 - Accuracy: 0.7278\n",
            "Epoch 10/100 - Loss: 1.0588 - Accuracy: 0.7345\n",
            "Epoch 11/100 - Loss: 1.0181 - Accuracy: 0.7419\n",
            "Epoch 12/100 - Loss: 0.9863 - Accuracy: 0.7461\n",
            "Epoch 13/100 - Loss: 0.9561 - Accuracy: 0.7521\n",
            "Epoch 14/100 - Loss: 0.9327 - Accuracy: 0.7546\n",
            "Epoch 15/100 - Loss: 0.9155 - Accuracy: 0.7563\n",
            "Epoch 16/100 - Loss: 0.8930 - Accuracy: 0.7614\n",
            "Epoch 17/100 - Loss: 0.8746 - Accuracy: 0.7646\n",
            "Epoch 18/100 - Loss: 0.8585 - Accuracy: 0.7674\n",
            "Epoch 19/100 - Loss: 0.8424 - Accuracy: 0.7701\n",
            "Epoch 20/100 - Loss: 0.8300 - Accuracy: 0.7739\n",
            "Epoch 21/100 - Loss: 0.8193 - Accuracy: 0.7737\n",
            "Epoch 22/100 - Loss: 0.8110 - Accuracy: 0.7732\n",
            "Epoch 23/100 - Loss: 0.7953 - Accuracy: 0.7772\n",
            "Epoch 24/100 - Loss: 0.7891 - Accuracy: 0.7786\n",
            "Epoch 25/100 - Loss: 0.7776 - Accuracy: 0.7801\n",
            "Epoch 26/100 - Loss: 0.7711 - Accuracy: 0.7820\n",
            "Epoch 27/100 - Loss: 0.7618 - Accuracy: 0.7839\n",
            "Epoch 28/100 - Loss: 0.7551 - Accuracy: 0.7858\n",
            "Epoch 29/100 - Loss: 0.7459 - Accuracy: 0.7853\n",
            "Epoch 30/100 - Loss: 0.7395 - Accuracy: 0.7876\n",
            "Epoch 31/100 - Loss: 0.7366 - Accuracy: 0.7873\n",
            "Epoch 32/100 - Loss: 0.7264 - Accuracy: 0.7931\n",
            "Epoch 33/100 - Loss: 0.7222 - Accuracy: 0.7923\n",
            "Epoch 34/100 - Loss: 0.7163 - Accuracy: 0.7937\n",
            "Epoch 35/100 - Loss: 0.7130 - Accuracy: 0.7933\n",
            "Epoch 36/100 - Loss: 0.7058 - Accuracy: 0.7965\n",
            "Epoch 37/100 - Loss: 0.7035 - Accuracy: 0.7953\n",
            "Epoch 38/100 - Loss: 0.7000 - Accuracy: 0.7955\n",
            "Epoch 39/100 - Loss: 0.6933 - Accuracy: 0.7970\n",
            "Epoch 40/100 - Loss: 0.6907 - Accuracy: 0.7982\n",
            "Epoch 41/100 - Loss: 0.6835 - Accuracy: 0.7999\n",
            "Epoch 42/100 - Loss: 0.6800 - Accuracy: 0.8004\n",
            "Epoch 43/100 - Loss: 0.6778 - Accuracy: 0.8003\n",
            "Epoch 44/100 - Loss: 0.6749 - Accuracy: 0.8013\n",
            "Epoch 45/100 - Loss: 0.6691 - Accuracy: 0.8010\n",
            "Epoch 46/100 - Loss: 0.6647 - Accuracy: 0.8033\n",
            "Epoch 47/100 - Loss: 0.6612 - Accuracy: 0.8054\n",
            "Epoch 48/100 - Loss: 0.6596 - Accuracy: 0.8050\n",
            "Epoch 49/100 - Loss: 0.6575 - Accuracy: 0.8042\n",
            "Epoch 50/100 - Loss: 0.6534 - Accuracy: 0.8068\n",
            "Epoch 51/100 - Loss: 0.6537 - Accuracy: 0.8050\n",
            "Epoch 52/100 - Loss: 0.6487 - Accuracy: 0.8073\n",
            "Epoch 53/100 - Loss: 0.6471 - Accuracy: 0.8067\n",
            "Epoch 54/100 - Loss: 0.6423 - Accuracy: 0.8076\n",
            "Epoch 55/100 - Loss: 0.6426 - Accuracy: 0.8064\n",
            "Epoch 56/100 - Loss: 0.6385 - Accuracy: 0.8101\n",
            "Epoch 57/100 - Loss: 0.6350 - Accuracy: 0.8104\n",
            "Epoch 58/100 - Loss: 0.6341 - Accuracy: 0.8097\n",
            "Epoch 59/100 - Loss: 0.6289 - Accuracy: 0.8117\n",
            "Epoch 60/100 - Loss: 0.6255 - Accuracy: 0.8133\n",
            "Epoch 61/100 - Loss: 0.6252 - Accuracy: 0.8115\n",
            "Epoch 62/100 - Loss: 0.6234 - Accuracy: 0.8132\n",
            "Epoch 63/100 - Loss: 0.6221 - Accuracy: 0.8143\n",
            "Epoch 64/100 - Loss: 0.6223 - Accuracy: 0.8141\n",
            "Epoch 65/100 - Loss: 0.6221 - Accuracy: 0.8113\n",
            "Epoch 66/100 - Loss: 0.6209 - Accuracy: 0.8132\n",
            "Epoch 67/100 - Loss: 0.6145 - Accuracy: 0.8155\n",
            "Epoch 68/100 - Loss: 0.6130 - Accuracy: 0.8141\n",
            "Epoch 69/100 - Loss: 0.6089 - Accuracy: 0.8174\n",
            "Epoch 70/100 - Loss: 0.6089 - Accuracy: 0.8167\n",
            "Epoch 71/100 - Loss: 0.6099 - Accuracy: 0.8161\n",
            "Epoch 72/100 - Loss: 0.6049 - Accuracy: 0.8184\n",
            "Epoch 73/100 - Loss: 0.6040 - Accuracy: 0.8186\n",
            "Epoch 74/100 - Loss: 0.6033 - Accuracy: 0.8191\n",
            "Epoch 75/100 - Loss: 0.6040 - Accuracy: 0.8176\n",
            "Epoch 76/100 - Loss: 0.6006 - Accuracy: 0.8180\n",
            "Epoch 77/100 - Loss: 0.5981 - Accuracy: 0.8188\n",
            "Epoch 78/100 - Loss: 0.5959 - Accuracy: 0.8193\n",
            "Epoch 79/100 - Loss: 0.5971 - Accuracy: 0.8197\n",
            "Epoch 80/100 - Loss: 0.5953 - Accuracy: 0.8187\n",
            "Epoch 81/100 - Loss: 0.5958 - Accuracy: 0.8208\n",
            "Epoch 82/100 - Loss: 0.5917 - Accuracy: 0.8229\n",
            "Epoch 83/100 - Loss: 0.5913 - Accuracy: 0.8214\n",
            "Epoch 84/100 - Loss: 0.5891 - Accuracy: 0.8219\n",
            "Epoch 85/100 - Loss: 0.5849 - Accuracy: 0.8236\n",
            "Epoch 86/100 - Loss: 0.5847 - Accuracy: 0.8236\n",
            "Epoch 87/100 - Loss: 0.5850 - Accuracy: 0.8215\n",
            "Epoch 88/100 - Loss: 0.5854 - Accuracy: 0.8218\n",
            "Epoch 89/100 - Loss: 0.5811 - Accuracy: 0.8254\n",
            "Epoch 90/100 - Loss: 0.5820 - Accuracy: 0.8226\n",
            "Epoch 91/100 - Loss: 0.5820 - Accuracy: 0.8236\n",
            "Epoch 92/100 - Loss: 0.5793 - Accuracy: 0.8240\n",
            "Epoch 93/100 - Loss: 0.5769 - Accuracy: 0.8241\n",
            "Epoch 94/100 - Loss: 0.5764 - Accuracy: 0.8265\n",
            "Epoch 95/100 - Loss: 0.5763 - Accuracy: 0.8252\n",
            "Epoch 96/100 - Loss: 0.5746 - Accuracy: 0.8238\n",
            "Epoch 97/100 - Loss: 0.5736 - Accuracy: 0.8251\n",
            "Epoch 98/100 - Loss: 0.5732 - Accuracy: 0.8261\n",
            "Epoch 99/100 - Loss: 0.5703 - Accuracy: 0.8257\n",
            "Epoch 100/100 - Loss: 0.5697 - Accuracy: 0.8278\n",
            "Hyperparams: lr=0.0005, batch_size=128, num_epochs=100 -> Test Accuracy: 0.8342\n",
            "Best Hyperparams: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 50} with Test Accuracy: 0.8759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F_fc9QyQRM08"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}